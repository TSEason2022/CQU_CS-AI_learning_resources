{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da33f9db-5291-4ebc-a69e-faf1d1403ea9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For 'context.set_context', package type mindspore-gpu support 'device_target' type gpu or cpu, but got Ascend.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6922/2911175023.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# 设置MindSpore的执行模式和设备\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPH_MODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Ascend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/_checkparam.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbound_unreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                     \u001b[0m_set_record\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/_checkparam.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                         raise TypeError(\"The argument {} must be {}, but got {}\"\n\u001b[1;32m   1058\u001b[0m                                         .format(name, bound_types[name], type(value)))\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/context.py\u001b[0m in \u001b[0;36mset_context\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms_ctx_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__device_target__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m             raise ValueError(f\"For 'context.set_context', package type {__package_name__} support 'device_target' \"\n\u001b[0m\u001b[1;32m    901\u001b[0m                              f\"type {__device_target__}, but got {device}.\")\n\u001b[1;32m    902\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms_ctx_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: For 'context.set_context', package type mindspore-gpu support 'device_target' type gpu or cpu, but got Ascend."
     ]
    }
   ],
   "source": [
    "# -- 实验环境导入 --\n",
    "# 隐藏警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#easydict模块用于以属性的方式访问字典的值\n",
    "from easydict import EasyDict as edict\n",
    "#os模块主要用于处理文件和目录\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mindspore\n",
    "#导入mindspore框架数据集\n",
    "import mindspore.dataset as ds\n",
    "#vision.c_transforms模块是处理图像增强的高性能模块，用于数据增强图像数据改进训练模型。\n",
    "from mindspore.dataset.vision import c_transforms as vision\n",
    "from mindspore import context\n",
    "import mindspore.nn as nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.nn.optim.momentum import Momentum\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n",
    "from mindspore import Tensor\n",
    "from mindspore.train.serialization import export\n",
    "from mindspore.train.loss_scale_manager import FixedLossScaleManager\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "import mindspore.ops as ops\n",
    "\n",
    "# 设置MindSpore的执行模式和设备\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "\n",
    "\n",
    "# -- 定义模型的相关变量 --\n",
    "cfg = edict({\n",
    "'data_path': 'flower_photos_train',\n",
    "'test_path':'flower_photos_test',\n",
    "'data_size': 3616,\n",
    "'HEIGHT': 240, # 图片高度\n",
    "'WIDTH': 320, # 图片宽度\n",
    "'_R_MEAN': 123.68,\n",
    "'_G_MEAN': 116.78,\n",
    "'_B_MEAN': 103.94,\n",
    "'_R_STD': 1.0,\n",
    "'_G_STD': 1.0,\n",
    "'_B_STD':1.0,\n",
    "'_RESIZE_SIDE_MIN': 256,\n",
    "'_RESIZE_SIDE_MAX': 512,\n",
    "'batch_size': 32,\n",
    "'num_class': 5, # 分类类别\n",
    "'epoch_size': 150, # 训练次数\n",
    "'loss_scale_num':1024,\n",
    "'prefix': 'resnet-ai',\n",
    "'directory': './model_resnet',\n",
    "'save_checkpoint_steps': 10,\n",
    "})\n",
    "\n",
    "\n",
    "# -- 数据集读取及预处理 --\n",
    "# 数据处理\n",
    "def read_data(path,config,usage=\"train\"):\n",
    "    #从目录中读取图像的源数据集。\n",
    "    dataset = ds.ImageFolderDataset(path,\n",
    "    class_indexing=\n",
    "    {'daisy':0,'dandelion':1,'roses':2,'sunflowers':3,'tulips':4})\n",
    "    # define map operations\n",
    "    decode_op = vision.Decode()\n",
    "    normalize_op = vision.Normalize(mean=[cfg._R_MEAN, cfg._G_MEAN,\n",
    "    cfg._B_MEAN], std=[cfg._R_STD, cfg._G_STD, cfg._B_STD])\n",
    "    resize_op = vision.Resize(cfg._RESIZE_SIDE_MIN)\n",
    "    center_crop_op = vision.CenterCrop((cfg.HEIGHT, cfg.WIDTH))\n",
    "    horizontal_flip_op = vision.RandomHorizontalFlip()\n",
    "    channelswap_op = vision.HWC2CHW()\n",
    "    random_crop_decode_resize_op = vision.RandomCropDecodeResize((cfg.HEIGHT,\n",
    "    cfg.WIDTH), (0.5, 1.0), (1.0, 1.0), max_attempts=100)\n",
    "    \n",
    "\n",
    "    if usage == 'train':\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=random_crop_decode_resize_op)\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=horizontal_flip_op)\n",
    "\n",
    "    else:\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=decode_op)\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=resize_op)\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=center_crop_op)\n",
    "        \n",
    "    dataset = dataset.map(input_columns=\"image\", operations=normalize_op)\n",
    "    dataset = dataset.map(input_columns=\"image\", operations=channelswap_op)\n",
    "    \n",
    "    if usage == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size=10000) # 10000 as in imageNet train script\n",
    "        dataset = dataset.batch(cfg.batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        dataset = dataset.batch(1, drop_remainder=True)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset.map_model = 4\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "de_train = read_data(cfg.data_path,cfg,usage=\"train\")\n",
    "de_test = read_data(cfg.test_path,cfg,usage=\"test\")\n",
    "print('训练数据集数量：',de_train.get_dataset_size()*cfg.batch_size)\n",
    "print('测试数据集数量：',de_test.get_dataset_size())\n",
    "de_dataset = de_train\n",
    "data_next = de_dataset.create_dict_iterator(output_numpy=True).__next__()\n",
    "print('通道数/图像高/宽：', data_next['image'][0,...].shape)\n",
    "print('一张图像的标签样式：', data_next['label'][0]) # 一共5类，用0-4的数字表达类别。\n",
    "plt.figure()\n",
    "plt.imshow(data_next['image'][0,0,...])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -- 神经网络定义 --\n",
    "# 定义ResidualBlockBase类实现Building Block结构\n",
    "from typing import Type, Union, List, Optional\n",
    "from mindvision.classification.models.blocks import ConvNormActivation\n",
    "from mindspore import nn\n",
    "\n",
    "class ResidualBlockBase(nn.Cell):\n",
    "    expansion: int = 1  # 最后一个卷积核数量与第一个卷积核数量相等\n",
    "\n",
    "    def __init__(self, in_channel: int, out_channel: int,\n",
    "                 stride: int = 1, norm: Optional[nn.Cell] = None,\n",
    "                 down_sample: Optional[nn.Cell] = None) -> None:\n",
    "        super(ResidualBlockBase, self).__init__()\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = ConvNormActivation(in_channel, out_channel,\n",
    "                                        kernel_size=3, stride=stride, norm=norm)\n",
    "        self.conv2 = ConvNormActivation(out_channel, out_channel,\n",
    "                                        kernel_size=3, norm=norm, activation=None)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"ResidualBlockBase construct.\"\"\"\n",
    "        identity = x  # shortcuts分支\n",
    "\n",
    "        out = self.conv1(x)  # 主分支第一层：3*3卷积层\n",
    "        out = self.conv2(out)  # 主分支第二层：3*3卷积层\n",
    "\n",
    "        if self.down_sample:\n",
    "            identity = self.down_sample(x)\n",
    "        out += identity  # 输出为主分支与shortcuts之和\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 定义ResidualBlock类实现Bottleneck结构\n",
    "class ResidualBlock(nn.Cell):\n",
    "    expansion = 4  # 最后一个卷积核的数量是第一个卷积核数量的4倍\n",
    "\n",
    "    def __init__(self, in_channel: int, out_channel: int,\n",
    "                 stride: int = 1, norm: Optional[nn.Cell] = None,\n",
    "                 down_sample: Optional[nn.Cell] = None) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "\n",
    "        self.conv1 = ConvNormActivation(in_channel, out_channel,\n",
    "                                        kernel_size=1, norm=norm)\n",
    "        self.conv2 = ConvNormActivation(out_channel, out_channel,\n",
    "                                        kernel_size=3, stride=stride, norm=norm)\n",
    "        self.conv3 = ConvNormActivation(out_channel, out_channel * self.expansion,\n",
    "                                        kernel_size=1, norm=norm, activation=None)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x  # shortscuts分支\n",
    "\n",
    "        out = self.conv1(x)  # 主分支第一层：1*1卷积层\n",
    "        out = self.conv2(out)  # 主分支第二层：3*3卷积层\n",
    "        out = self.conv3(out)  # 主分支第三层：1*1卷积层\n",
    "\n",
    "        if self.down_sample:\n",
    "            identity = self.down_sample(x)\n",
    "\n",
    "        out += identity  # 输出为主分支与shortcuts之和\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 定义make_layer实现残差块的构建\n",
    "def make_layer(last_out_channel, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "               channel: int, block_nums: int, stride: int = 1):\n",
    "    down_sample = None  # shortcuts分支\n",
    "\n",
    "    if stride != 1 or last_out_channel != channel * block.expansion:\n",
    "        down_sample = ConvNormActivation(last_out_channel, channel * block.expansion,\n",
    "                                         kernel_size=1, stride=stride, norm=nn.BatchNorm2d, activation=None)\n",
    "\n",
    "    layers = []\n",
    "    layers.append(block(last_out_channel, channel, stride=stride, down_sample=down_sample, norm=nn.BatchNorm2d))\n",
    "\n",
    "    in_channel = channel * block.expansion\n",
    "    # 堆叠残差网络\n",
    "    for _ in range(1, block_nums):\n",
    "        layers.append(block(in_channel, channel, norm=nn.BatchNorm2d))\n",
    "\n",
    "    return nn.SequentialCell(layers)\n",
    "\n",
    "# 实现ResNet50模型的构建\n",
    "from mindvision.classification.models.classifiers import BaseClassifier\n",
    "from mindvision.classification.models.head import DenseHead\n",
    "from mindvision.classification.models.neck import GlobalAvgPooling\n",
    "from mindvision.classification.utils.model_urls import model_urls\n",
    "from mindvision.utils.load_pretrained_model import LoadPretrainedModel\n",
    "\n",
    "class ResNet(nn.Cell):\n",
    "    def __init__(self, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "                 layer_nums: List[int], norm: Optional[nn.Cell] = None) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "        # 第一个卷积层，输入channel为3（彩色图像），输出channel为64\n",
    "        self.conv1 = ConvNormActivation(3, 64, kernel_size=7, stride=2, norm=norm)\n",
    "        # 最大池化层，缩小图片的尺寸\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same')\n",
    "        # 各个残差网络结构块定义，\n",
    "        self.layer1 = make_layer(64, block, 64, layer_nums[0])\n",
    "        self.layer2 = make_layer(64 * block.expansion, block, 128, layer_nums[1], stride=2)\n",
    "        self.layer3 = make_layer(128 * block.expansion, block, 256, layer_nums[2], stride=2)\n",
    "        self.layer4 = make_layer(256 * block.expansion, block, 512, layer_nums[3], stride=2)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(arch: str, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "            layers: List[int], num_classes: int, pretrained: bool, input_channel: int):\n",
    "    backbone = ResNet(block, layers)\n",
    "    neck = GlobalAvgPooling()  # 平均池化层\n",
    "    head = DenseHead(input_channel=input_channel, num_classes=num_classes)  # 全连接层\n",
    "    model = BaseClassifier(backbone, neck, head)  # 将backbone层、neck层和head层连接起来\n",
    "\n",
    "    if pretrained:\n",
    "        # 下载并加载预训练模型\n",
    "        LoadPretrainedModel(model, model_urls[arch]).run()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(num_classes: int = 1000, pretrained: bool = False):\n",
    "    \"ResNet50模型\"\n",
    "    return _resnet(\"resnet50\", ResidualBlock, [3, 4, 6, 3], num_classes, pretrained, 2048)\n",
    "\n",
    "\n",
    "# -- 模型训练与评估 --\n",
    "from mindspore.train import Model\n",
    "from mindvision.engine.callback import ValAccMonitor\n",
    "\n",
    "# 定义ResNet50网络\n",
    "network = resnet50(pretrained=True)\n",
    "\n",
    "# 全连接层输入层的大小\n",
    "in_channel = network.head.dense.in_channels\n",
    "head = DenseHead(input_channel=in_channel, num_classes=5)\n",
    "# 重置全连接层\n",
    "network.head = head\n",
    "# 设置步长\n",
    "step_size = de_train.get_dataset_size()\n",
    "# 设置学习率\n",
    "num_epochs = 40\n",
    "lr = nn.cosine_decay_lr(min_lr=0.00001, max_lr=0.001, total_step=step_size * num_epochs,\n",
    "                        step_per_epoch=step_size, decay_epoch=num_epochs)\n",
    "# 定义优化器和损失函数\n",
    "opt = nn.Momentum(params=network.trainable_params(), learning_rate=lr, momentum=0.9)\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "# 实例化模型\n",
    "model = Model(network, loss, opt, metrics={\"Accuracy\": nn.Accuracy()})\n",
    "# 模型训练\n",
    "#model.train(num_epochs, de_train, callbacks=[ValAccMonitor(model, de_test, num_epochs)])\n",
    "\n",
    "\n",
    "# -- 可视化模型预测 --\n",
    "import matplotlib.pyplot as plt\n",
    "from mindspore import Tensor\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mindspore as ms\n",
    "\n",
    "# 计算在测试集上的预测准确率\n",
    "def calculate_accuracy(best_ckpt_path, val_de):\n",
    "    # 生成神经网络\n",
    "    num_class = 5\n",
    "    net = resnet50(num_class)\n",
    "    # 加载模型参数\n",
    "    param_dict = load_checkpoint(best_ckpt_path)\n",
    "    load_param_into_net(net, param_dict)\n",
    "    model = Model(net)\n",
    "\n",
    "    # 显示图像及图像的预测值  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterator = val_de.create_dict_iterator(output_numpy=True)   \n",
    "    for i, data in enumerate(iterator):\n",
    "        # 预测图像类别\n",
    "        output = model.predict(Tensor(data['image']))\n",
    "        pred = np.argmax(output.asnumpy(), axis=1)      \n",
    "        if pred[0] == data['label'][0]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        if i >= 47:\n",
    "            break\n",
    "    \n",
    "    # 计算在测试集上的准确率\n",
    "    accuracy = correct / total\n",
    "    print('Test accuracy:', accuracy)\n",
    "\n",
    "# 展示对样例图片的预测结果\n",
    "def show_sample(image_path, label, ckpt_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize((320, 240))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # 归一化处理\n",
    "    mean=[cfg._R_MEAN, cfg._G_MEAN, cfg._B_MEAN] \n",
    "    std=[cfg._R_STD, cfg._G_STD, cfg._B_STD]\n",
    "    image = np.array(image)\n",
    "    image = (image - mean) / std\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # 图像通道由(h, w, c)转换为(c, h, w)\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "    # 扩展数据维数为(1, c, h, w)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # 生成神经网络\n",
    "    num_class = 5\n",
    "    net = resnet50(num_class)\n",
    "    # 加载模型参数\n",
    "    param_dict = ms.load_checkpoint(ckpt_path)\n",
    "    ms.load_param_into_net(net, param_dict)\n",
    "    model = ms.Model(net)\n",
    "\n",
    "    # 模型预测\n",
    "    pre = model.predict(ms.Tensor(image))\n",
    "    result = np.argmax(pre)\n",
    "    class_name = {0: \"daisy\", 1: \"dandelion\", 2: \"roses\", 3: \"sunflowers\", 4: \"tulips\"}  \n",
    "    # 如果预测正确颜色为绿色，预测错误为红色\n",
    "    color = 'green' if class_name[result] == label else 'red'\n",
    "    plt.title(f\"Predict: {class_name[result]}\\nlabel:{label}\", color=color)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "# 计算准确率\n",
    "calculate_accuracy('best.ckpt', de_test)\n",
    "\n",
    "# 展示测试样例\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "image1 = \"./flower_photo_sample/daisy.jpg\"\n",
    "plt.subplot(1, 5, 1)\n",
    "show_sample(image1, \"daisy\", 'best.ckpt')\n",
    "\n",
    "image2 = \"./flower_photo_sample/dandelion.jpg\"\n",
    "plt.subplot(1, 5, 2)\n",
    "show_sample(image2, \"dandelion\", 'best.ckpt')\n",
    "\n",
    "image3 = \"./flower_photo_sample/roses.jpg\"\n",
    "plt.subplot(1, 5, 3)\n",
    "show_sample(image3, \"roses\", 'best.ckpt')\n",
    "\n",
    "image4 = \"./flower_photo_sample/sunflowers.jpg\"\n",
    "plt.subplot(1, 5, 4)\n",
    "show_sample(image4, \"sunflowers\", 'best.ckpt')\n",
    "\n",
    "image5 = \"./flower_photo_sample/tulips.jpg\"\n",
    "plt.subplot(1, 5, 5)\n",
    "show_sample(image5, \"tulips\", 'best.ckpt')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b0d9656-1658-43f5-93d4-6e92e9cded41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建文件夹\n",
    "if not os.path.exists('./flowers/'):\n",
    "    os.mkdir('./flowers/')\n",
    "param_dict = load_checkpoint(os.path.join('best.ckpt'))\n",
    "# load the parameter into net\n",
    "resnet=resnet50(cfg.num_class)\n",
    "load_param_into_net(resnet, param_dict)\n",
    "x = np.random.uniform(-1.0, 1.0, size = [1, 3, cfg.HEIGHT,cfg.WIDTH]).astype(np.float32)\n",
    "export(resnet, Tensor(x), file_name = './flowers/best_model.onnx',file_format = 'ONNX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ab2d905-f81c-4dab-98ab-49184ee21e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v2.1.0.5d9c87c8-5d9c87c8\n",
      "INFO:root:Using OBS-Python-SDK-3.20.9.1\n"
     ]
    }
   ],
   "source": [
    "import moxing\n",
    "moxing.file.copy_parallel(src_url='./flowers/best_model.onnx',\n",
    "dst_url='s3://atri45/flower/onnx/best_model.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
