{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb3875a-ea57-403a-8b5d-a571d535703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入层结点数：4  隐藏层结点数：10  输出层结点数：3  训练次数：3000\n",
      "训练500次，损失为：1.409344  准确率：0.57\n",
      "训练1000次，损失为：1.053660  准确率：0.67\n",
      "训练1500次，损失为：0.851646  准确率：0.83\n",
      "训练2000次，损失为：0.663516  准确率：0.97\n",
      "训练2500次，损失为：0.528269  准确率：0.97\n",
      "训练3000次，损失为：0.442659  准确率：0.97\n",
      "训练后输入层与隐藏层之间的权值为：\n",
      "[[ 0.65843167 -1.62704722  0.87164282 -0.45133868  0.3900633  -1.18940435\n",
      "   1.00427913  0.80202447 -0.22162126  0.70354138]\n",
      " [ 0.24457636 -1.65966204  0.24634784 -0.9173418   1.14898661 -0.47759174\n",
      "   0.28912229  0.20637151 -0.83553253  0.56058568]\n",
      " [ 0.20134475  2.43309329  1.00064714  1.98516169 -1.8324379   1.22925721\n",
      "   0.78151734  0.01114742  1.3515743   0.58909234]\n",
      " [ 0.1709534   2.3608441   0.59836138  0.92092043 -0.44340953  1.86384225\n",
      "   0.39300065  0.28317122  1.2459687   0.92072782]]\n",
      "训练后输入层与隐藏层之间的偏置为：\n",
      "[0.38785268 0.82871958 0.53820543 0.47369905 0.52625045 0.27003703\n",
      " 0.21154925 0.94147836 0.19381407 0.85657204]\n",
      "训练后隐藏层与输出层之间的权值为：\n",
      "[[-0.18122761 -0.54510793 -0.22850712]\n",
      " [-1.75854509 -2.85678756  3.65217066]\n",
      " [ 0.49507284  0.20185519 -0.94440558]\n",
      " [-2.25313174  2.02448159  1.17509433]\n",
      " [ 2.56520049 -1.43856819 -1.26400752]\n",
      " [ 0.17031092 -1.55549112  1.79369134]\n",
      " [ 0.55560741  0.11007347 -0.50494775]\n",
      " [ 0.10516884 -0.2113598  -0.21111119]\n",
      " [-1.18326422  1.45613351 -0.10221963]\n",
      " [ 0.61539915 -0.07204099 -0.93966789]]\n",
      "训练后隐藏层与输出层之间的偏置为：\n",
      "[0.89860749 0.71776856 0.99903445]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 初始化参数\n",
    "def initialize_parameters(numIn, numHide, numOut):\n",
    "    # w1和b1为输入层与隐藏层之间的权重和偏置，w2和b2为隐藏层与输出层之间的权重和偏置\n",
    "    b1 = np.random.rand(numHide) \n",
    "    b2 = np.random.rand(numOut) \n",
    "    w1 = np.random.rand(numIn,numHide) \n",
    "    w2 = np.random.rand(numHide,numOut)\n",
    "    \n",
    "    # 通过字典存储参数\n",
    "    parameters = {'w1': w1, 'b1': b1, 'w2': w2, 'b2': b2}\n",
    "    return parameters\n",
    "\n",
    "# 定义 sigmoid函数\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "# 前向传播\n",
    "def forward_propagation(x, parameters):\n",
    "    # w1和b1为输入层与隐藏层之间的权重和偏置，w2和b2为隐藏层与输出层之间的权重和偏置\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    # 使用sigmoid函数作为激活函数，a1和z1为输入层与隐藏层之间的输入和输出，w2和b2为隐藏层与输出层之间的输入和输出\n",
    "    a1 = np.dot(x,w1)-b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1,w2)-b2 \n",
    "    z2 = sigmoid(a2)\n",
    "\n",
    "    cache = {'a1': a1, 'z1': z1, 'a2': a2, 'z2': z2}\n",
    "    return z2,cache\n",
    "\n",
    "# 计算损失\n",
    "def loss(z2, y, m):\n",
    "    # 采用交叉熵函数作为损失函数\n",
    "    cost = - np.sum(np.multiply(np.log(z2), y) + np.multiply((1 - y), np.log(1 - z2))) / m\n",
    "    return cost\n",
    "\n",
    "# 反向传播\n",
    "def backward_propagation(parameters, cache, x, y, n):\n",
    "    w2 = parameters['w2']\n",
    "    z1 = cache['z1']\n",
    "    z2 = cache['z2']\n",
    "\n",
    "    # 根据链式法则推导求导公式，计算e_w1、e_b1、e_w2、e_b2\n",
    "    g = z2*(1-z2)*(y-z2) \n",
    "    e_w2 = np.dot(z1.T,g)\n",
    "    e_b2 = -np.mean(g, axis=0)\n",
    "\n",
    "    e = z1*(1-z1)*np.dot(g,w2.T)\n",
    "    e_w1 = np.dot(x.T, e) \n",
    "    e_b1= -np.mean(e, axis=0)\n",
    "    \n",
    "    grads = {'e_w1': e_w1, 'e_b1': e_b1, 'e_w2': e_w2, 'e_b2': e_b2}\n",
    "    return grads\n",
    "\n",
    "# 更新参数\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    "    e_w1 = grads['e_w1']\n",
    "    e_b1 = grads['e_b1']\n",
    "    e_w2 = grads['e_w2']\n",
    "    e_b2 = grads['e_b2']\n",
    "\n",
    "    w1 = w1 + e_w1 * learning_rate\n",
    "    b1 = b1 + e_b1 * learning_rate\n",
    "    w2 = w2 + e_w2 * learning_rate\n",
    "    b2 = b2 + e_b2 * learning_rate\n",
    "\n",
    "    parameters = {'w1': w1, 'b1': b1, 'w2': w2, 'b2': b2}\n",
    "    return parameters\n",
    "\n",
    "# 测试函数\n",
    "def test(parameters, x_test, y_test, m):\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    # 使用训练后得到的参数进行前向传播得到预测值\n",
    "    a1 = np.dot(x_test,w1)-b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1,w2)-b2 \n",
    "    z2 = sigmoid(a2)\n",
    "    \n",
    "    # 对预测值分类\n",
    "    output = np.zeros((m, 3), dtype=int)\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(3):\n",
    "            if z2[i][j] > 0.5:\n",
    "                output[i][j] = 1\n",
    "            else:\n",
    "                output[i][j] = 0\n",
    "                \n",
    "    yuce=np.zeros(m,dtype=int)  \n",
    "    \n",
    "    for i in range(m):\n",
    "        if output[i][0]==1 and output[i][1]==0 and output[i][2]==0:\n",
    "            yuce[i]=1\n",
    "        elif output[i][0]==0 and output[i][1]==1 and output[i][2]==0:\n",
    "            yuce[i]=2\n",
    "        elif output[i][0]==0 and output[i][1]==0 and output[i][2]==1:\n",
    "            yuce[i]=3\n",
    "\n",
    "    # 计算正确率\n",
    "    right_num = 0\n",
    "    for j in range(m):\n",
    "        if yuce[j] == y_test[j] :\n",
    "            right_num = right_num + 1\n",
    "    right_rate = right_num / m \n",
    "\n",
    "    return right_rate\n",
    "\n",
    "# 顶层模块，调用各函数组成BP神经网络模型\n",
    "def neural_model(x, y, x_test, y_test, numIn, numHide, numOut, numIterations): \n",
    "    print('输入层结点数：%i  隐藏层结点数：%i  输出层结点数：%i  训练次数：%i' %(numIn,numHide,numOut,numIterations))\n",
    "    n = x.shape[0]\n",
    "    m = x_test.shape[0]\n",
    "    # 初始化参数\n",
    "    parameters = initialize_parameters(numIn, numHide, numOut)\n",
    "    for i in range(numIterations):\n",
    "        # 前向传播\n",
    "        z2, cache = forward_propagation(x, parameters)\n",
    "        # 计算损失\n",
    "        cost = loss(z2, y, n)\n",
    "        # 反向传播\n",
    "        grads = backward_propagation(parameters, cache, x, y, n)\n",
    "        # 更新参数\n",
    "        parameters = update_parameters(parameters, grads, 0.001)\n",
    "        # 进行测试\n",
    "        \n",
    "        # 打印输出损失和正确率\n",
    "        if (i + 1) % 500 == 0:         \n",
    "            right_rate = test(parameters, x_test, y_test, m)\n",
    "            print('训练%i次，损失为：%f  准确率：%.2f' % (i+1,cost,right_rate))\n",
    "            \n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']   \n",
    "    print('训练后输入层与隐藏层之间的权值为：')\n",
    "    print(w1)\n",
    "    print('训练后输入层与隐藏层之间的偏置为：')\n",
    "    print(b1.T)\n",
    "    print('训练后隐藏层与输出层之间的权值为：')\n",
    "    print(w2)\n",
    "    print('训练后隐藏层与输出层之间的偏置为：')\n",
    "    print(b2.T)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 读取数据\n",
    "    x = []\n",
    "    y = []\n",
    "    result = []\n",
    "    with open('鸢尾花数据集.txt', 'r') as f:\n",
    "        data = f.readlines()\n",
    "    # 打乱数据顺序\n",
    "    random.shuffle(data)\n",
    "    # 读取参数x，结果y，值result\n",
    "    for line in data:\n",
    "        values = line.strip().split(',')\n",
    "        x.append([float(v) for v in values[:-1]])\n",
    "        if values[4] == 'setosa':  # setosa赋值1\n",
    "            y.append([1,0,0])\n",
    "            result.append(1)\n",
    "        elif values[4] == 'versicolor':  # versicolor赋值2\n",
    "            y.append([0,1,0])\n",
    "            result.append(2)\n",
    "        elif values[4] == 'virginica':  # virginica赋值3\n",
    "            y.append([0,0,1])\n",
    "            result.append(3)\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    result = np.array(result)  \n",
    "    # 划分训练集和测试集\n",
    "    x_train = x[:120]\n",
    "    y_train = y[:120]\n",
    "    x_test = x[120:]\n",
    "    y_test = result[120:]\n",
    "\n",
    "    # 使用BP神经网络模型进行训练，输入层4个结点，隐藏层1个结点，输出层1个结点，训练200次\n",
    "    parameters = neural_model(x, y, x_test, y_test, 4, 10, 3, 3000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec420c1f-7b1c-4fd6-ba09-6ff944c6b2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac048b-2e8b-4c2e-843a-1528d3876859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b87f4b-220f-40ff-81c5-db51dc0bb21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
