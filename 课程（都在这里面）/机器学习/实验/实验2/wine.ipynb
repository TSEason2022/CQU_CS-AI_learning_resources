{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1394d3-6e16-45fe-b7dc-05f8e9d26f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入层结点数：13  隐藏层结点数：40  输出层结点数：3  训练次数：10000\n",
      "训练1000次，损失为：1.528038  准确率：0.68\n",
      "训练2000次，损失为：0.887053  准确率：0.86\n",
      "训练3000次，损失为：0.598045  准确率：0.93\n",
      "训练4000次，损失为：0.571902  准确率：0.93\n",
      "训练5000次，损失为：0.452456  准确率：0.96\n",
      "训练6000次，损失为：0.450502  准确率：0.89\n",
      "训练7000次，损失为：0.646465  准确率：0.93\n",
      "训练8000次，损失为：0.449911  准确率：0.89\n",
      "训练9000次，损失为：0.390662  准确率：0.93\n",
      "训练10000次，损失为：0.384657  准确率：0.93\n",
      "训练后输入层与隐藏层之间的权值为：\n",
      "[[ 6.82684652e-02  1.39954761e-03  3.25483813e-02  7.28897138e-02\n",
      "   4.90873215e-03  5.03081057e-02  6.79849203e-03  1.52053972e-02\n",
      "  -1.28874378e-01 -2.33558130e-03 -3.78618666e-02 -1.19710239e-02\n",
      "   8.38456696e-03 -4.08479931e-02 -4.46852328e-02 -5.45757509e-02\n",
      "   7.36369125e-02  8.91131289e-02 -3.94667955e-02 -4.61436276e-02\n",
      "  -3.27233623e-02  8.50821438e-02  9.63874551e-02  5.50362590e-03\n",
      "  -1.63118553e-01 -5.12665599e-02  9.99739791e-02 -7.85051275e-02\n",
      "  -6.38894270e-02  6.12697803e-02  7.00789315e-02 -3.09789129e-02\n",
      "   2.29646632e-02 -3.02123810e-02 -6.32001952e-02  6.61359545e-02\n",
      "   6.92970184e-02  8.40663904e-02  3.94955168e-02  9.06977039e-03]\n",
      " [-3.47674584e-01  1.54083239e-01 -7.67509220e-01 -3.05091883e-01\n",
      "   1.26432444e-02  5.60362704e-01  1.05336162e-02  6.32286621e-01\n",
      "  -6.78021583e-01  1.23525543e-03 -3.82294756e-02  1.31961700e-02\n",
      "   6.73452878e-03  1.53428454e-01  2.48262473e-01  5.25202098e-01\n",
      "  -1.38133392e-01  3.23302647e-01  4.85817255e-01 -1.47740702e-03\n",
      "  -1.09624791e+00 -2.98911250e-01 -6.00409119e-01  3.85125880e-03\n",
      "  -7.85139695e-01  1.03305148e-01 -5.86088058e-01  3.73122973e-01\n",
      "   1.07777970e-01 -4.10224677e-01 -2.28842473e-01  1.14986651e-02\n",
      "  -6.18564769e-01  1.95211783e-01  3.53159936e-01 -3.56097289e-01\n",
      "  -4.23853566e-01 -1.12284992e-01  4.15888599e-01  6.44520857e-03]\n",
      " [ 3.22435198e-02  8.56170983e-03 -4.65243549e-01  5.79816290e-02\n",
      "   6.21833585e-03  3.74486485e-01  4.60585967e-03  2.63313641e-01\n",
      "  -7.42862711e-01 -5.10560861e-03 -2.43006764e-02 -1.25028206e-02\n",
      "   3.21307528e-03  3.63264909e-02  2.06217111e-03  3.27881691e-01\n",
      "   1.05442325e-01  4.46359175e-01  1.02417106e-01 -1.70548310e-02\n",
      "  -5.72232336e-01  7.48895728e-03  7.23381743e-02 -2.07807478e-03\n",
      "  -9.09495628e-01 -5.61673817e-02 -3.30295991e-01  2.04466729e-01\n",
      "  -7.27295867e-02  6.28889095e-02  5.10298504e-02 -4.89035158e-02\n",
      "  -4.09720916e-01 -9.53279081e-04  1.53162384e-01 -2.52183289e-03\n",
      "   4.66715249e-02  2.78839385e-01  2.60675706e-01  6.03732467e-03]\n",
      " [-3.52541816e-02 -1.01964543e-01  1.13368799e+00 -1.56800784e-02\n",
      "   2.81387489e-02  6.83456255e-02  2.79396363e-02  5.71789886e-01\n",
      "   1.83927681e+00  1.09495475e-02 -1.00942582e-01 -3.47589540e-03\n",
      "   3.05396075e-02 -1.47747192e-02 -7.83498575e-02 -9.37868849e-01\n",
      "  -5.43033713e-03  1.41323234e-01  3.64322815e-01 -9.73349258e-02\n",
      "   3.27390914e-01 -1.10345660e-01 -7.80670760e-01  1.80268581e-02\n",
      "   1.17129616e+00  5.80077070e-03  1.32705994e+00 -1.04081554e+00\n",
      "  -3.36937478e-02 -4.53720100e-01  9.09494094e-02  3.47760077e-02\n",
      "   8.16852616e-01 -8.60738173e-03 -4.12950560e-01 -8.54501670e-02\n",
      "  -2.27440940e-01 -5.43393590e-01  1.92361032e-01  2.47504535e-02]\n",
      " [ 2.56897583e-01 -1.11903691e-01 -1.48410545e-01  1.15308313e-01\n",
      "   1.01660667e-01 -1.02172136e-01  1.02872969e-01 -2.02698203e-01\n",
      "  -7.81883493e-02  1.03785102e-01  5.25029552e-02  1.09694740e-01\n",
      "   1.01981731e-01 -1.13694878e-02 -1.33732688e-01  1.59221790e-01\n",
      "  -1.78875722e-01 -1.60330013e-01 -1.15150691e-01  4.86059225e-02\n",
      "   7.76916089e-02  1.73987636e-02  1.63037278e-01  1.00927202e-01\n",
      "   9.65488618e-02  1.18289260e-02 -2.80667452e-01  2.29830069e-01\n",
      "   2.77265389e-02  2.57903335e-01  1.98303426e-01 -7.13632042e-02\n",
      "  -1.04766670e-01 -1.29010292e-01  4.58079759e-02  3.02865601e-02\n",
      "   2.20833356e-01  1.37770332e-02 -9.01162821e-02  1.03337793e-01]\n",
      " [ 4.55441298e-01 -7.83212769e-02  4.84367839e-01  4.95116273e-01\n",
      "   1.57205121e-03  6.96939483e-02  5.31002273e-04 -6.78780026e-02\n",
      "  -6.58145965e-01 -1.09723857e-02 -7.49473842e-02 -3.86014618e-02\n",
      "  -5.48673879e-05 -1.55676516e-01 -2.90694028e-01 -4.16827950e-01\n",
      "   5.11993331e-01  7.40331992e-01 -2.97840601e-01 -1.16020831e-01\n",
      "   3.53521681e-02  4.47499954e-01  7.62968403e-01 -2.15082585e-02\n",
      "  -8.55077600e-01 -3.26076348e-01  7.85613111e-01 -4.52656160e-01\n",
      "  -4.06588987e-01  5.49326478e-01  4.26309558e-01 -1.44518476e-01\n",
      "   3.99695793e-01 -2.39155668e-01 -2.62456651e-01  3.91929514e-01\n",
      "   5.54319549e-01  9.84762689e-01  6.54935682e-02  1.26573096e-03]\n",
      " [ 1.01949992e+00 -1.50297680e-01  4.60256865e-01  1.05469784e+00\n",
      "  -9.69679168e-03  3.74503328e-01 -7.17130504e-03 -8.59051604e-02\n",
      "  -1.84513417e+00 -4.46084682e-02 -2.71215124e-01 -1.29695285e-01\n",
      "  -1.10567943e-02 -3.72524671e-01 -6.33655344e-01 -7.93356622e-01\n",
      "   1.03881016e+00  1.40366148e+00 -6.72624771e-01 -3.47111552e-01\n",
      "  -1.70486345e-01  1.02962637e+00  1.51153176e+00 -6.36740060e-02\n",
      "  -2.13245543e+00 -7.01919455e-01  1.10406591e+00 -8.55022023e-01\n",
      "  -8.46814042e-01  1.13358186e+00  8.95895265e-01 -3.60467239e-01\n",
      "   5.80366946e-01 -5.14520319e-01 -5.40456284e-01  8.87933217e-01\n",
      "   1.19617877e+00  1.73196498e+00  2.88844904e-01 -7.94209349e-03]\n",
      " [ 1.15920967e-02  1.26296393e-02  6.10768003e-02  9.52119365e-03\n",
      "   8.63376405e-03 -6.54190569e-02  3.32637091e-03 -3.22559694e-02\n",
      "   1.25996453e-01  1.15647457e-02 -1.42962439e-02 -6.44082370e-04\n",
      "   6.64233033e-03 -3.63060265e-02 -2.12960807e-02 -3.96247871e-02\n",
      "  -7.74829468e-03 -7.23072908e-02 -2.60999500e-02 -3.07388125e-02\n",
      "   1.10454032e-01  4.71992693e-02 -3.36374128e-02  8.70314934e-03\n",
      "   1.69111516e-01 -2.18602991e-02  5.21490139e-02 -4.71255195e-02\n",
      "  -2.51039404e-02 -2.58632939e-02  1.77933381e-02 -3.43631396e-03\n",
      "   4.03162108e-02 -4.73648599e-03 -7.49690637e-02  2.89314692e-02\n",
      "  -8.26546952e-03 -8.36957158e-02 -4.49411625e-02  7.15310257e-03]\n",
      " [ 4.10179632e-01 -6.31799788e-02  5.89791043e-01  4.19157337e-01\n",
      "   2.81365797e-03 -6.08533190e-02  4.34680792e-03 -1.05141081e-01\n",
      "  -1.56164848e-01 -1.72157875e-02 -6.66613730e-02 -3.82575415e-02\n",
      "   1.42867147e-03 -1.41234073e-01 -2.51681944e-01 -6.75634886e-01\n",
      "   4.03219078e-01  4.47023287e-01 -2.58126534e-01 -9.74455367e-02\n",
      "   2.56572442e-01  3.87919499e-01  4.70913591e-01 -1.34271259e-02\n",
      "  -3.24080318e-01 -2.36664108e-01  8.66687797e-01 -6.21928044e-01\n",
      "  -3.14657135e-01  4.16252147e-01  3.63356001e-01 -1.03194245e-01\n",
      "   6.28833270e-01 -2.04220362e-01 -3.05588720e-01  3.47379593e-01\n",
      "   4.57448573e-01  6.74639641e-01 -2.36660190e-02  5.28805348e-03]\n",
      " [-7.71101973e-01  4.97866263e-01 -2.09056739e+00 -7.33496075e-01\n",
      "   6.18001394e-03  2.07542060e+00  5.80295881e-03  1.39522635e+00\n",
      "  -1.22670653e+00  7.58477636e-03  2.78829085e-02  2.64396498e-02\n",
      "   2.26304321e-03  4.06187447e-01  6.31143267e-01  1.57465820e+00\n",
      "  -3.24246495e-01  1.29210773e+00  1.03260856e+00  9.29209699e-02\n",
      "  -3.02551378e+00 -6.89936921e-01 -1.19167336e+00 -8.88796073e-04\n",
      "  -2.76424402e+00  3.25518782e-01 -1.43874396e+00  9.96706023e-01\n",
      "   3.46607102e-01 -8.22234806e-01 -5.54429816e-01  1.97540831e-03\n",
      "  -1.90962273e+00  4.55308139e-01  1.03580314e+00 -7.79953980e-01\n",
      "  -9.05819784e-01 -4.77204132e-01  1.41196107e+00  7.51007999e-05]\n",
      " [ 2.22209399e-01 -5.30495357e-02  4.01286693e-01  2.27967637e-01\n",
      "   8.99590496e-03 -2.58143486e-01  8.30378478e-03 -2.17422628e-01\n",
      "   1.16313510e-01 -5.25411809e-04 -5.69303974e-02 -1.42430076e-02\n",
      "   7.34616721e-03 -1.34964386e-01 -1.72137892e-01 -3.25440668e-01\n",
      "   1.68371269e-01 -7.01044534e-02 -2.35424767e-01 -1.02164986e-01\n",
      "   4.55479996e-01  2.49394855e-01  3.03076877e-01  1.43853566e-03\n",
      "   2.37295464e-01 -1.54120859e-01  3.56912363e-01 -2.54636126e-01\n",
      "  -1.76245122e-01  2.13289090e-01  2.03605186e-01 -5.13293179e-02\n",
      "   3.42403804e-01 -1.26190803e-01 -2.83979012e-01  2.32735234e-01\n",
      "   2.47147211e-01  1.41247425e-01 -1.81905204e-01  3.71812986e-03]\n",
      " [ 7.12288812e-01 -1.43117211e-01  1.78289732e-01  7.67373374e-01\n",
      "  -2.87438637e-03  7.49871017e-02  1.19019244e-03 -6.08547595e-02\n",
      "  -1.52044210e+00 -3.70853456e-02 -1.92207150e-01 -9.19073172e-02\n",
      "  -1.78506535e-03 -2.62893877e-01 -4.78091234e-01 -4.34188546e-01\n",
      "   7.34801265e-01  9.11416511e-01 -4.58419695e-01 -2.42353646e-01\n",
      "  -1.47242676e-02  6.94591329e-01  1.07831602e+00 -4.17173050e-02\n",
      "  -1.59817155e+00 -5.14716602e-01  5.87473623e-01 -4.89296785e-01\n",
      "  -6.28146171e-01  7.93555257e-01  6.49826735e-01 -2.55878030e-01\n",
      "   2.75781742e-01 -3.83290552e-01 -4.01714550e-01  6.19506209e-01\n",
      "   8.34275095e-01  1.22135215e+00  7.71884207e-02  1.79957812e-03]\n",
      " [ 8.48531665e-02  2.82892643e-02 -9.97964796e-01  1.12000139e-01\n",
      "   1.31226940e-03  5.07027608e-01 -9.68359911e-04  3.66646066e-01\n",
      "  -1.36658773e+00 -1.85401378e-02 -4.61007012e-02 -3.60324529e-02\n",
      "  -7.53216368e-04  5.82964968e-02  2.32566978e-03  6.07513198e-01\n",
      "   2.18903302e-01  6.70288872e-01  1.05124871e-01 -3.26435401e-02\n",
      "  -9.05919606e-01  3.33397007e-02  2.07584793e-01 -2.23184433e-02\n",
      "  -1.63515824e+00 -9.76169467e-02 -7.30563834e-01  4.58517743e-01\n",
      "  -1.25195753e-01  1.77013666e-01  9.95045316e-02 -9.17023822e-02\n",
      "  -7.25739034e-01 -2.24819894e-02  3.11783027e-01  6.59676414e-03\n",
      "   1.31096048e-01  6.55320836e-01  3.28172879e-01 -4.78797639e-04]]\n",
      "训练后输入层与隐藏层之间的偏置为：\n",
      "[-3.08119662e-05  9.08925372e-03  5.48419139e-03  3.37505027e-03\n",
      "  3.01804988e-03  2.07314724e-03  6.31336104e-03  7.11752006e-03\n",
      "  5.00105014e-03  9.92578409e-03  4.47299720e-03  5.47148624e-04\n",
      "  3.00295753e-04  3.17387789e-03  5.59728599e-03  8.74379249e-03\n",
      " -7.20983778e-05  3.96876401e-03  2.34203528e-03  6.15783933e-03\n",
      "  7.08704465e-03  7.40874695e-03  2.23257211e-03  6.68467741e-03\n",
      " -5.15090944e-04  2.85136537e-03  4.11484234e-03  8.27643821e-03\n",
      "  8.15168260e-03  3.71645184e-03  7.64652549e-03  1.55795902e-03\n",
      "  3.52404126e-03  4.54448112e-03  5.69262871e-03  2.32578846e-03\n",
      "  4.69433932e-03  6.35886523e-03  4.49237368e-03  8.72603810e-03]\n",
      "训练后隐藏层与输出层之间的权值为：\n",
      "[[ 0.31678682  0.48581698 -0.64972752]\n",
      " [-0.03513635 -0.27263784  0.27745529]\n",
      " [-1.11871095  0.65810342 -0.53602126]\n",
      " [ 0.42062719  0.42620787 -0.7126714 ]\n",
      " [-0.67692515 -0.04010205  0.11197516]\n",
      " [ 0.77871865 -1.05639376  0.32418238]\n",
      " [-0.68800483 -0.02407166  0.10822451]\n",
      " [-0.10422162 -0.61113813  0.57782464]\n",
      " [-1.50443668  1.02521596  0.98964798]\n",
      " [-0.6447428  -0.08638507  0.13547051]\n",
      " [-0.34989767 -0.39974753  0.2955243 ]\n",
      " [-0.50670076 -0.21004069  0.18969042]\n",
      " [-0.67977499 -0.03218702  0.11371184]\n",
      " [-0.34872748 -0.30522168  0.36320741]\n",
      " [-0.40455663 -0.32109133  0.46875147]\n",
      " [ 0.27766601 -0.79707162  0.91122417]\n",
      " [ 0.49367626  0.14541304 -0.75714857]\n",
      " [ 1.17505722 -0.83227782 -0.88484477]\n",
      " [-0.56195147 -0.47979217  0.72391926]\n",
      " [-0.36161358 -0.36925426  0.36126576]\n",
      " [-0.87490203  0.86539928 -0.54278166]\n",
      " [ 0.53836248  0.44264202 -0.92728517]\n",
      " [ 1.12001993  0.74634772 -1.57530995]\n",
      " [-0.62021624 -0.10114997  0.14318317]\n",
      " [-1.1280955   1.14481791  0.55503145]\n",
      " [-0.52091578 -0.23183443  0.55383929]\n",
      " [-1.20920855  1.21519403 -0.86741762]\n",
      " [ 0.31012381 -0.98227692  0.85731687]\n",
      " [-0.62541251 -0.28445044  0.62869079]\n",
      " [ 0.52430123  0.37203583 -0.85565275]\n",
      " [ 0.26478983  0.29376569 -0.59018345]\n",
      " [-0.27798933 -0.18187216  0.25570924]\n",
      " [-0.70528197  0.63336564 -0.82551105]\n",
      " [-0.33759814 -0.23080007  0.34635312]\n",
      " [-0.18231757 -0.49705956  0.75181869]\n",
      " [ 0.2224059   0.3841437  -0.61171434]\n",
      " [ 0.47969043  0.55866827 -0.8157536 ]\n",
      " [ 1.34001345 -0.26641643 -1.48694687]\n",
      " [ 0.49406679 -0.85074012  0.22061031]\n",
      " [-0.68101887 -0.03067974  0.10677869]]\n",
      "训练后隐藏层与输出层之间的偏置为：\n",
      "[0.00496506 0.00425136 0.00107763]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 初始化参数\n",
    "def initialize_parameters(numIn, numHide, numOut):\n",
    "    # w1和b1为输入层与隐藏层之间的权重和偏置，w2和b2为隐藏层与输出层之间的权重和偏置\n",
    "    b1 = np.random.rand(numHide) *0.01\n",
    "    b2 = np.random.rand(numOut) *0.01\n",
    "    w1 = np.random.rand(numIn,numHide) *0.01\n",
    "    w2 = np.random.rand(numHide,numOut) *0.01\n",
    "    \n",
    "    # 通过字典存储参数\n",
    "    parameters = {'w1': w1, 'b1': b1, 'w2': w2, 'b2': b2}\n",
    "    return parameters\n",
    "\n",
    "# 定义sigmoid函数\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "# 前向传播\n",
    "def forward_propagation(x, parameters):\n",
    "    # w1和b1为输入层与隐藏层之间的权重和偏置，w2和b2为隐藏层与输出层之间的权重和偏置\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    # 使用sigmoid函数作为激活函数，a1和z1为输入层与隐藏层之间的输入和输出，w2和b2为隐藏层与输出层之间的输入和输出\n",
    "    a1 = np.dot(x,w1)-b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1,w2)-b2 \n",
    "    z2 = sigmoid(a2)\n",
    "\n",
    "    cache = {'a1': a1, 'z1': z1, 'a2': a2, 'z2': z2}\n",
    "    return z2,cache\n",
    "\n",
    "# 计算损失\n",
    "def loss(z2, y, m):\n",
    "    # 采用交叉熵函数作为损失函数\n",
    "    cost = - np.sum(np.multiply(np.log(z2), y) + np.multiply((1 - y), np.log(1 - z2))) / m\n",
    "    return cost\n",
    "\n",
    "# 反向传播\n",
    "def backward_propagation(parameters, cache, x, y, n):\n",
    "    w2 = parameters['w2']\n",
    "    z1 = cache['z1']\n",
    "    z2 = cache['z2']\n",
    "\n",
    "    # 根据链式法则推导求导公式，计算e_w1、e_b1、e_w2、e_b2\n",
    "    g = z2*(1-z2)*(y-z2) \n",
    "    e_w2 = np.dot(z1.T,g)\n",
    "    e_b2 = -np.mean(g, axis=0)\n",
    "\n",
    "    e = z1*(1-z1)*np.dot(g,w2.T)\n",
    "    e_w1 = np.dot(x.T, e) \n",
    "    e_b1= -np.mean(e, axis=0)\n",
    "    \n",
    "    grads = {'e_w1': e_w1, 'e_b1': e_b1, 'e_w2': e_w2, 'e_b2': e_b2}\n",
    "    return grads\n",
    "\n",
    "# 更新参数\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    "    e_w1 = grads['e_w1']\n",
    "    e_b1 = grads['e_b1']\n",
    "    e_w2 = grads['e_w2']\n",
    "    e_b2 = grads['e_b2']\n",
    "\n",
    "    w1 = w1 + e_w1 * learning_rate\n",
    "    b1 = b1 + e_b1 * learning_rate\n",
    "    w2 = w2 + e_w2 * learning_rate\n",
    "    b2 = b2 + e_b2 * learning_rate\n",
    "\n",
    "    parameters = {'w1': w1, 'b1': b1, 'w2': w2, 'b2': b2}\n",
    "    return parameters\n",
    "\n",
    "# 测试函数\n",
    "def test(parameters, x_test, y_test, m):\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    # 使用训练后得到的参数进行前向传播得到预测值\n",
    "    a1 = np.dot(x_test,w1)-b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1,w2)-b2 \n",
    "    z2 = sigmoid(a2)\n",
    "    \n",
    "    # 对预测值分类\n",
    "    output = np.zeros((m, 3), dtype=int)\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(3):\n",
    "            if z2[i][j] > 0.5:\n",
    "                output[i][j] = 1\n",
    "            else:\n",
    "                output[i][j] = 0\n",
    "                \n",
    "    yuce=np.zeros(m,dtype=int)  \n",
    "    \n",
    "    for i in range(m):\n",
    "        if output[i][0]==1 and output[i][1]==0 and output[i][2]==0:\n",
    "            yuce[i]=1\n",
    "        elif output[i][0]==0 and output[i][1]==1 and output[i][2]==0:\n",
    "            yuce[i]=2\n",
    "        elif output[i][0]==0 and output[i][1]==0 and output[i][2]==1:\n",
    "            yuce[i]=3\n",
    "\n",
    "    # 计算正确率\n",
    "    right_num = 0\n",
    "    for j in range(m):\n",
    "        if yuce[j] == y_test[j] :\n",
    "            right_num = right_num + 1\n",
    "    right_rate = right_num / m \n",
    "\n",
    "    return right_rate\n",
    "\n",
    "# 顶层模块，调用各函数组成BP神经网络模型\n",
    "def neural_model(x, y, x_test, y_test, numIn, numHide, numOut, numIterations): \n",
    "    print('输入层结点数：%i  隐藏层结点数：%i  输出层结点数：%i  训练次数：%i' %(numIn,numHide,numOut,numIterations))\n",
    "    n = x.shape[0]\n",
    "    m = x_test.shape[0]\n",
    "    # 初始化参数\n",
    "    parameters = initialize_parameters(numIn, numHide, numOut)\n",
    "    for i in range(numIterations):\n",
    "        # 前向传播\n",
    "        z2, cache = forward_propagation(x, parameters)\n",
    "        # 计算损失\n",
    "        cost = loss(z2, y, n)\n",
    "        # 反向传播\n",
    "        grads = backward_propagation(parameters, cache, x, y, n)\n",
    "        # 更新参数\n",
    "        parameters = update_parameters(parameters, grads, 0.001)\n",
    "        # 进行测试\n",
    "        \n",
    "        # 每20次训练，打印输出一次损失和正确率\n",
    "        if (i + 1) % 1000 == 0:         \n",
    "            right_rate = test(parameters, x_test, y_test, m)\n",
    "            print('训练%i次，损失为：%f  准确率：%.2f' % (i+1,cost,right_rate))\n",
    "            \n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']   \n",
    "    print('训练后输入层与隐藏层之间的权值为：')\n",
    "    print(w1)\n",
    "    print('训练后输入层与隐藏层之间的偏置为：')\n",
    "    print(b1.T)\n",
    "    print('训练后隐藏层与输出层之间的权值为：')\n",
    "    print(w2)\n",
    "    print('训练后隐藏层与输出层之间的偏置为：')\n",
    "    print(b2.T)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 读取数据\n",
    "    x = []\n",
    "    y = []\n",
    "    result = []\n",
    "    with open('wine.txt', 'r') as f:\n",
    "        data = f.readlines()\n",
    "    # 打乱数据顺序\n",
    "    random.shuffle(data)\n",
    "    # 读取参数x，结果y，值result\n",
    "    for line in data:\n",
    "        values = line.strip().split(',')\n",
    "        x.append([float(v) for v in values[1:]])\n",
    "        if values[0] == '1':\n",
    "            y.append([1,0,0])\n",
    "            result.append(1)\n",
    "        elif values[0] == '2':\n",
    "            y.append([0,1,0])\n",
    "            result.append(2)\n",
    "        elif values[0] == '3':\n",
    "            y.append([0,0,1])\n",
    "            result.append(3)\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    result = np.array(result)\n",
    "    # 对x元素进行处理\n",
    "    x[:, 0] *= 0.1\n",
    "    x[:, 12] *= 0.001    \n",
    "    # 划分训练集和测试集\n",
    "    x_train = x[:150]\n",
    "    y_train = y[:150]\n",
    "    x_test = x[150:]\n",
    "    y_test = result[150:]\n",
    "\n",
    "    # 使用BP神经网络模型进行训练，输入层13个结点，隐藏层40个结点，输出层3个结点，训练10000次\n",
    "    parameters = neural_model(x, y, x_test, y_test, 13, 40, 3, 10000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b330ce-a54b-48d7-a964-f88ff5ee13f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66d0b5-72fc-4377-94ff-01746fe0a478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ec719-a3a9-4cb5-9e3e-5160a474491c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
